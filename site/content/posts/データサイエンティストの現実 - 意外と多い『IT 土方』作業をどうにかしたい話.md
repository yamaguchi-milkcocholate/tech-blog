---
author: "Teppei Yamaguchi"
title: "データサイエンティストの現実 - 意外と多い『IT 土方』作業をどうにかしたい話"
date: "2025-11-09T09:00:00+09:00"
description: "モデリングの単純作業を AI に任せてモデリング業務を半自動化した話"
tags:
  [
    "#AI",
    "#エンジニア",
    "#モデル",
    "#業務効率化",
    "#自動化",
    "#生産性向上",
    "#AIと学び",
    "#データサイエンス",
    "#データサイエンティスト",
    "#AIと協働",
  ]
categories: ["themes", "syntax"]
series: ["Themes Guide"]
aliases: ["migrate-from-jekyl"]
cover:
  image: https://raw.githubusercontent.com/yamaguchi-milkcocholate/tech-blog/refs/heads/main/site/static/images/covers/%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%83%86%E3%82%A3%E3%82%B9%E3%83%88%E3%80%81AI%E3%81%A8%E5%8D%94%E5%83%8D%E3%81%99%E3%82%8B.jpg
  caption: "tmp"
ShowToc: true
TocOpen: true
draft: false
---

# データサイエンティストの現実 - 意外と多い『IT 土方』作業をどうにかしたい話

## TL;DR

最初にこの記事で言いたいことは、

**データサイエンティストは AI で単純作業を減らして、頭使うところに集中した方が上手いモデリングができる**

です！

そんなのデータサイエンティスト限らずどの業界でもそうだろ。ってツッコみたくなりますよね。何を当たり前のことをと。

でも意外とできてないんじゃないでしょうか？ 少なくとも私はそう思っています。

思い返せばこれって自動化できるよな、ってことたくさんあると思います。

そこで今回はモデリングについて、AI を活用してみました！

## データサイエンスの現実 - 意外と多いよ IT 土方作業

データサイエンティストと聞くと、華やかなイメージがありますよね？

AI で未来を予測し、データから新しい発見を生み出す...

私もそんなイメージをもって新卒でデータサイエンティストになりました。

でも実際の現場は違いました笑

実は意外と「IT 土木」的な単純作業が多いんです。

---

### 現実のデータサイエンス業務の内訳（異論は認めます）

#### 理想のイメージ（実態は全体の 30%くらいかな、、、）

- **ホワイトボードで仮説立案・検証方針の議論**  
  みんなでわいわい

- **最新論文を読んでアルゴリズム選定**  
  I'm a scientist. (⌐■_■)

- **モデルの解釈と示唆の導出**  
  モデルのお気持ちがわかるぜ〜

---

#### 現実の大部分（その他 70%）

- 実験設定ファイルのパラメータ調整／実行コマンドのコピペ・修正  
  `→` 仕様を変えながら実験。 私調べでは v3 くらいから訳わかんなくなる

- 結果ファイルの整理と比較作業  
  `→` エクセル使いガチ。報告資料に貼る画像ファイルもいっぱい。 ファイルが訳わかんなくなる

- 「あの実験の設定、何だったっけ？」問題  
  `→` 言うまでもなく 訳わかんなくなる

- ログファイルを漁って異常値の原因調査  
  `→` アドホックなスクリプトが増殖して 1 週間後には訳わかんなくなる

- 実験番号とファイル名の整合性チェック  
  `→` バージョン名は一応つけてるだけで 進むほど訳わかんなくなる

---

#### 実際に私がやらかした具体例

**パラメータ管理の沼**：

```yaml
# これ、実験003だっけ？004だっけ？
learning_rate: 0.05 # なぜこの値にしたんだっけ...
num_leaves: 31 # 前回から変えてない？変えた？
```

---

**ファイル命名の悩み**：

```bash
models/
├── model_v1.pkl          # 何のモデル？
├── latest_model.pkl      # 本当にlatest？
├── model_good.pkl        # どう良かったの？
└── model_20251103.pkl    # 日付だけじゃわからない
```

---

**実行コマンドの迷子**：

```bash
# 3週間前の成功した実験、どのコマンドだったっけ...
python train.py --config ??? --data ??? --output ???
```

---

## モデリングの上手さってなんだろう

話は変わって、データサイエンティストのモデリングの上手さってどう表現できると思いますか？

私は、こう考えています。

$$
\text{精度向上} = (\text{仮説設定の質}) \times (\text{試行サイクル数})
$$

前提として、モデリングは下記のような実験サイクルの繰り返しだと考えています。

```mermaid
flowchart LR
    A[1. 仮設設定] --> B[2. 実験目的設定]
    B --> C[3. 実装]
    C --> D[4. 実行]
    D --> E[5. 結果分析]
    E --> F[6. 改善仮説立案]
    F --> G[7. 次回計画]
    G --> A
```

---

**仮説検証の質**  
仮説検証の質が関係するのは下記なのではないかと考えています。

この部分は AI よりも経験豊かなデータサイエンティストが頑張れるところだと思います。

- 1. 仮設設定／2. 実験目的設定／6. 改善仮説立案／7. 次回計画  
     `→` ビジネス → モデリングへの要件落とし込み・結果から学びを得る深さ・課題解決の引出し、など

---

**試行サイクル数**  
試行サイクル数のボトルネックになるのが、

- 3. 実装／4. 実行／5. 結果分析  
     `→` 先ほど述べた **「IT 土木」的な単純作業**がこれらにあたります

---

## ここまでの話をまとめると

モデリングの上手さを決めるのは、

- 仮説設定の質
- 試行サイクル数

ですが、

&nbsp;&nbsp;&nbsp;&nbsp;「試行サイクル」を回すための単純作業に時間を奪われる  
`→` 「仮説設定」を考える時間が削られる  
`→` 実験回数を増やしたくても、管理コストで諦める  
`→` 結果として、精度向上の機会を逃す

なんてことになってそうと言うことです。

---

mlflow など実験管理ツールを導入すれば解決するのでは？ってツッコミがありそうですね。

たしかにその通りです…

でもライトかつスピーディーに検証を試したいときには初期導入コスト重すぎませんか？

---

本格運用でのモデル実験管理／メトリクス追跡／チーム共有には最適な一方で、

ビジネス要件も考えつつ、タスク設計も固めつつ、でもモデリングをちょっと試したいなんてときには大げさすぎる。というのが私の印象です。

---

## 結局、どうすればいいの？

この検証サイクルが重くなる問題は、多くのデータサイエンティストが抱えている課題だと思います。

でも私たちデータサイエンティストは幸い AI をよく知る立場にあります。

- 実装
- 実行
- 結果分析

これらを AI に任せることができれば...？

データサイエンティストは本来やるべき「仮説設定」「検証方針の立案」「結果の解釈」に集中できるはずです。

**次回の記事では、実際に AI と協働でモデリング業務を半自動化した体験談をお話しします。**

実験サイクルを 高速に回せるようになった具体的な手法と、そこで見えてきた「AI 協働の新しい可能性」について、実際のログと成果を交えながら書いてみる予定です。

---

_この記事が「単純作業に疲れた」データサイエンティストの皆さんの参考になれば嬉しいです！_
